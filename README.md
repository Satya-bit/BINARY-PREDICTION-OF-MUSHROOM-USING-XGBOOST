# BINARY-PREDICTION-OF-MUSHROOM-USING-XGBOOST(POISONOUS OR EDIBLE)?
This project aims at predicting whether the mushroom is poisonous or edible 

I recently participated in my first Kaggle Tabular Playground Challenge focused on binary prediction of poisonous mushrooms and am thrilled to announce that I ranked in the top 25% of the competition! With a Matthews Correlation Coefficient public score of 0.98492 and a private score of 0.98479, I secured the 569th position out of 2,424 participants.

-What is the Kaggle Tabular Playground Challenge?
Kaggle's Tabular Playground Challenges are monthly competitions designed to help data enthusiasts sharpen their skills in a collaborative environment. These challenges often focus on tabular datasets, providing a great platform for practicing data analysis, feature engineering, and model tuning.

-About the Data
The dataset for this challenge included 21 different features such as cap shape, cap diameter, gill shape, stem height, stem width, etc. with a total of around 3,116,945 rows. The main challenge was effectively handling missing values while maintaining model accuracy. This competition aimed to predict whether the mushrooms were poisonous or edible.

-What I Learned
Throughout the competition, I gained valuable experience in several key areas:
Exploratory Data Analysis (EDA): I deepened my understanding of how to explore and visualize data to uncover hidden patterns and insights.
Data Cleaning: I learned techniques to clean the data, including handling missing values and preparing numerical and categorical columns for modeling.
Machine Learning Algorithms: I explored advanced ensemble algorithms like CatBoost and XGBoost, which played a crucial role in achieving high model performance.
Hyperparameter Tuning with Optuna: I used the Optuna framework to fine-tune my modelâ€™s hyperparameters, leading to improved accuracy.

-What is Optuna?
Optuna is an open-source hyperparameter optimization framework that allows you to automate the process of tuning hyperparameters in machine learning models. It uses a combination of intelligent sampling techniques to efficiently explore the hyperparameter space, making it easier to find the optimal settings for your model.
